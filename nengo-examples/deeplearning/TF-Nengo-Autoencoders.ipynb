{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Autoencoder With TensorNodes\n",
    "\n",
    "When working with TensorNodes you can train them just like normal parts of a Nengo model. The only deviation from the standard procedure is the definition of the custom classes which encapsulate the TensorFlow portions. \n",
    "\n",
    "In this example we will illustrate this trainability by training an autoencoder on the MNIST dataset. The autoencoder takes the input in with a dimensionality of `784` (28\\*28) and reduces it to a dimensionality of `36`. This is the encoding phase where the network is effectively compressing the input. The decode phase then takes that `36` dimensional representation and attempts to reconstruct the original input with it.\n",
    "\n",
    "We show at the bottom of the notebook how the training changes the output. The output starts off as pure noise and gradually looks more and more like the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture consists of one input layer followed by 4 densely connected layers. The layers architecture is mirrored such that:\n",
    "\n",
    "```\n",
    "Layer 1: 784 Elements - Input\n",
    "Layer 2: 128 Elements - Encode 1\n",
    "Layer 3: 36 Elements - Encode 2\n",
    "Layer 4: 128 Elements - Decode 1\n",
    "Layer 5: 784 Elements - Decode 2/Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 128 # 1st layer num features\n",
    "n_hidden_2 = 36 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorNodes are broken up into two classes: an Encoder, which compresses the input, and a Decoder, which decompresses the output to attempt to recreate the original.\n",
    "\n",
    "Both of the TensorNode types consist of two fully connected (dense) layers which are in turn connected to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "class Encoder(object):\n",
    "    def pre_build(self, shape_in, shape_out):\n",
    "        self.n_mini = shape_in[0]\n",
    "        self.size_in = shape_in[1]\n",
    "        self.size_out = shape_out[1]\n",
    "        \n",
    "    \n",
    "    def __call__(self, t, x):    \n",
    "        dense = tf.contrib.layers.fully_connected(x, n_hidden_1)\n",
    "        dense = tf.contrib.layers.fully_connected(dense, n_hidden_2)\n",
    "\n",
    "        return dense\n",
    "\n",
    "\n",
    "# Building the encoder\n",
    "class Decoder(object):\n",
    "    def pre_build(self, shape_in, shape_out):\n",
    "        self.n_mini = shape_in[0]\n",
    "        self.size_in = shape_in[1]\n",
    "        self.size_out = shape_out[1]\n",
    "    \n",
    "    def __call__(self, t, x):    \n",
    "        dense = tf.contrib.layers.fully_connected(x, n_hidden_1)\n",
    "        dense = tf.contrib.layers.fully_connected(dense, self.size_out)\n",
    "\n",
    "        return dense\n",
    "\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.RectifiedLinear()\n",
    "    net.config[nengo.Ensemble].gain = nengo.dists.Choice([1])\n",
    "    net.config[nengo.Ensemble].bias = nengo.dists.Choice([0])\n",
    "    \n",
    "     # create node to feed in images\n",
    "    inp = nengo.Node(nengo.processes.PresentInput(mnist.test.images, 0.001))\n",
    "    \n",
    "    # create TensorNodes to insert into the network\n",
    "    tf_encode = nengo_dl.TensorNode(Encoder(), size_in=n_input, size_out=n_hidden_2, label='H1')\n",
    "    tf_decode = nengo_dl.TensorNode(Decoder(), size_in=n_hidden_2, size_out=n_input, label='H2')\n",
    "    \n",
    "    # connecting all the nodes together\n",
    "    nengo.Connection(inp, tf_encode)\n",
    "    nengo.Connection(tf_encode, tf_decode)\n",
    "    \n",
    "    # defining probes\n",
    "    input_probe = nengo.Probe(inp)\n",
    "    encode_probe = nengo.Probe(tf_encode)\n",
    "    decode_probe = nengo.Probe(tf_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for this network the training data for output and input are the same, therefore the same data can be used for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {inp: mnist.train.images[:, None, :]}\n",
    "train_targets = {decode_probe: train_inputs[inp]}\n",
    "test_inputs = {inp: mnist.test.images[:, None, :]}\n",
    "test_targets = {decode_probe: test_inputs[inp]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break the training up into single epochs so that we can visualize the effect of the training over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Calculation finished in 0:00:00                                                \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a3f7976ee5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(losses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nengo_dl/simulator.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, data, objective, combine, extra_feeds, progress_bar, training)\u001b[0m\n\u001b[1;32m    703\u001b[0m             loss = self.run_batch(data, objective, extra_feeds=extra_feeds,\n\u001b[1;32m    704\u001b[0m                                   \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                                   combine=combine, training=training)\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# sum across objectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nengo_dl/simulator.py\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self, data, outputs, extra_feeds, extra_fetches, n_epochs, truncation, shuffle, profile, training, callback, combine, isolate_state)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# apply functions (if any) to output probes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0moutput_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# initialize any new variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nengo/utils/magic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 return self.wrapper(\n\u001b[0;32m--> 181\u001b[0;31m                     self.__wrapped__, self.instance, args, kwargs)\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nengo_dl/tensor_graph.py\u001b[0m in \u001b[0;36mwith_self\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nengo_dl/tensor_graph.py\u001b[0m in \u001b[0;36mbuild_outputs\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "n_examples = 100\n",
    "losses = []\n",
    "learning_rate = 0.05\n",
    "repetitions = 5\n",
    "with nengo_dl.Simulator(net, minibatch_size=n_examples) as sim:\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "    \n",
    "    for e in range(repetitions):\n",
    "        losses.append(sim.loss(test_inputs, test_targets, 'mse'))\n",
    "        print(losses)\n",
    "        \n",
    "        sim.step(input_feeds={inp: test_inputs[inp][:n_examples]})\n",
    "        \n",
    "        sim.train(train_inputs, train_targets, optimizer)\n",
    "        \n",
    "    sim.step(input_feeds={inp: test_inputs[inp][:n_examples]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the input on the top row, the compressed representation in the middle, and then the reconstructed output on the bottom. We can see that as training progresses (moving left to right) the reconstructions become more and more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-80b7e1d46065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_probe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_probe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode_probe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axis = plt.subplots(3, repetitions+1, figsize=(10, 5))\n",
    "for i in range(repetitions+1):\n",
    "    axis[0][i].imshow(np.reshape(sim.data[input_probe][0, i], (28, 28)))\n",
    "    axis[1][i].imshow(np.reshape(sim.data[encode_probe][0, i], (6, 6)))\n",
    "    axis[2][i].imshow(np.reshape(sim.data[decode_probe][0, i], (28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
